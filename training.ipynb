{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = '7b'\n",
    "output_dir = 'OUTPUTS'\n",
    "model_dir = 'models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8cde44136e443a6a9074fa04f8fa4ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/navarro/miniconda3/envs/py39/lib/python3.9/site-packages/transformers/utils/hub.py:374: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import util\n",
    "from util import create_model_tokenizer\n",
    "\n",
    "model, tokenizer = create_model_tokenizer(model_name, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22423059d51a4559b5c8a50248398994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10356 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dataset_prompt\n",
    "\n",
    "dataset = dataset_prompt.generate_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['conversation', 'summary', 'text'],\n",
       "        num_rows: 9320\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['conversation', 'summary', 'text'],\n",
       "        num_rows: 518\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['conversation', 'summary', 'text'],\n",
       "        num_rows: 518\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conversation': 'Para que serve Slow K?',\n",
       " 'summary': 'O Slow-K é um medicamento que trata e previne a da falta de potássio no organismo, devido a ingestão insuficiente pela alimentação ou por eliminação exagerada por doença, renal ou intestinal ou situações como diarreias, vômitos ou uso excessivo de laxantes.',\n",
       " 'text': \"[INST] <<SYS>>\\nYou are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\\n\\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\\n<</SYS>>\\nPara que serve Slow K?\\n[/INST]\\n\\nO Slow-K é um medicamento que trata e previne a da falta de potássio no organismo, devido a ingestão insuficiente pela alimentação ou por eliminação exagerada por doença, renal ou intestinal ou situações como diarreias, vômitos ou uso excessivo de laxantes.\"}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = util.prepare_model(model)\n",
    "#model = util.get_peft_model(model, util.get_lora_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size = 1, #The batch size per GPU (default: 8)\n",
    "    gradient_accumulation_steps = 1,\n",
    "    warmup_steps = 0, # Number of steps used for a linear warmup from 0 to learning_rate (default: 0)\n",
    "    num_train_epochs=10,\n",
    "   # weight_decay=0.1,\n",
    "    learning_rate = 1e-3,\n",
    "    fp16 = True, # Whether to use fp16 16-bit (mixed) precision training instead of 32-bit training.\n",
    "    logging_steps = 1, # Number of update steps between two logs if logging_strategy=\"steps\". Should be an integer or a float in range [0,1). \n",
    "    #If smaller than 1, will be interpreted as ratio of total training steps.\n",
    "    overwrite_output_dir = True,\n",
    "    evaluation_strategy = \"epoch\", #\"The evaluation strategy to adopt during training. \"\n",
    "    save_strategy = \"no\",\n",
    "    push_to_hub = False,\n",
    "    output_dir = output_dir,\n",
    "    report_to=\"tensorboard\",\n",
    "    optim=\"paged_adamw_8bit\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "444894b9b8934e75a9421ff8a0f22def",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9320 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b35cc555a58348a98b4de0d446f12056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/518 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "trainer_sft =  SFTTrainer(\n",
    "    model = model,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['valid'],\n",
    "    peft_config = util.get_lora_config(),\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = 2048,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/navarro/miniconda3/envs/py39/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/navarro/miniconda3/envs/py39/lib/python3.9/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='93200' max='93200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [93200/93200 15:38:33, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.755900</td>\n",
       "      <td>0.749058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.526900</td>\n",
       "      <td>0.749517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.026500</td>\n",
       "      <td>0.740227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.570200</td>\n",
       "      <td>0.692841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.511400</td>\n",
       "      <td>0.682139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.764500</td>\n",
       "      <td>0.650538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.319400</td>\n",
       "      <td>0.614566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.177500</td>\n",
       "      <td>0.593393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.821700</td>\n",
       "      <td>0.581771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.364200</td>\n",
       "      <td>0.581152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.config.use_cache = False\n",
    "trainer_sft.train()\n",
    "model.config.use_cache = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('models/7b/tokenizer_config.json',\n",
       " 'models/7b/special_tokens_map.json',\n",
       " 'models/7b/tokenizer.json')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_sft.save_model(f\"{model_dir}/{model_name}\")\n",
    "tokenizer.save_pretrained(f\"{model_dir}/{model_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
